BDEPEND=app-alternatives/ninja >=dev-build/cmake-3.20.5 >=dev-vcs/git-1.8.2.1[curl]
DEFINED_PHASES=compile configure install postinst prepare test unpack
DEPEND=mpi? ( virtual/mpi[cxx(+),threads(+)] ) cuda? ( >=dev-util/nvidia-cuda-toolkit-11.8.0[profiler(+)] ) clblast? ( sci-libs/clblast[opencl(+)] )
DESCRIPTION=Port of Facebook's LLaMA model in C/C++
EAPI=8
HOMEPAGE=https://github.com/ggerganov/llama.cpp
INHERIT=cmake cuda flag-o-matic git-r3
IUSE=cpu_flags_x86_avx cpu_flags_x86_avx2 cpu_flags_x86_avx512bw cpu_flags_x86_f16c cpu_flags_x86_fma3 clblast cuda cuda-fp16 +lto mpi
LICENSE=MIT
PROPERTIES=live
RDEPEND=mpi? ( virtual/mpi[cxx(+),threads(+)] ) cuda? ( >=dev-util/nvidia-cuda-toolkit-11.8.0[profiler(+)] ) clblast? ( sci-libs/clblast[opencl(+)] )
REQUIRED_USE=cuda-fp16? ( cuda ) !cuda? ( !cuda-fp16 ) ?? ( clblast cuda )
SLOT=0
_eclasses_=toolchain-funcs	e56c7649b804f051623c8bc1a1c44084	multilib	c19072c3cd7ac5cb21de013f7e9832e0	flag-o-matic	288c54efeb5e2aa70775e39032695ad4	multiprocessing	30ead54fa2e2b5f9cd4e612ffc34d0fe	ninja-utils	2df4e452cea39a9ec8fb543ce059f8d6	xdg-utils	baea6080dd821f5562d715887954c9d3	cmake	c7c9a62d6232cac66d4ea32d575c3e7c	cuda	283d0f298f6c196c755a0f8d50daca85	git-r3	fbb2889c81f3a05910c1524db69425c1
_md5_=554b28def84da4fbd91532a547bdfb5c
